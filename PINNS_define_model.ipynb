{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pltg\n",
    "\n",
    "#tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ffm(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, std_dev = 2):\n",
    "        super().__init__()\n",
    "        self.omega = nn.Parameter(torch.randn(out_dim, in_dim) * std_dev) # Length of hidden layer is rows, \n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cos(F.F.linear(x, self.omega))\n",
    "\n",
    "class PINNs_net(nn.Module):    \n",
    "    def __init__(self, in_dim=2, HL_dim=32, out_dim=1, activation=nn.Tanh()):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -------------\n",
    "        in_dim: the input dimensions - number of independant variables\n",
    "        HL_dim: the width of the network\n",
    "        out_dim: the output dimensions - number of dependant variables\n",
    "        activation: The activation function you wish to use in the network - the default is nn.Tanh()\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the network architecture\n",
    "        network = [nn.Linear(in_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, out_dim)]\n",
    "        '''network = [ffm(in_dim, HL_dim),\n",
    "                   nn.Linear(in_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, out_dim)]'''\n",
    "        \n",
    "        # define the network using sequential method\n",
    "        self.u = nn.Sequential(*network) \n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return self.u(torch.cat((x, t), 1))\n",
    "    \n",
    "    \n",
    "    def compute_loss(self, x, t, Nx, Nt):\n",
    "        \"\"\"\n",
    "        This is the physics part really\n",
    "        \"\"\"\n",
    "        x.requires_grad=True\n",
    "        t.requires_grad=True\n",
    "        u = self.u(torch.cat((x,t), 1))\n",
    "\n",
    "        # compute PDE derivatives using auto grad\n",
    "        u_t = grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0] # we need to specify the dimension of the output array\n",
    "        u_x = grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        \n",
    "        # set a loss function to apply to each of the physics residuals (PDE, IC, BC)\n",
    "        loss_fun = nn.MSELoss()\n",
    "\n",
    "        # compute the PDE residual loss\n",
    "        res = u_t - 0.1*u_xx\n",
    "        pde_loss = loss_fun(res, torch.zeros_like(res))\n",
    "\n",
    "        # compute the BC loss\n",
    "        u_reshaped = u.view(Nx, Nt) # [Nx*Nt, 1] -> [Nx, Nt]\n",
    "        u_x_reshaped = u_x.view(Nx, Nt) # [Nx*Nt, 1] -> [Nx, Nt]\n",
    "        bc_loss = loss_fun(u_reshaped[0, :], torch.zeros_like(u_reshaped[0,:])) \\\n",
    "                + loss_fun(u_reshaped[Nx-1, :], torch.zeros_like(u_reshaped[Nx-1,:])) \\\n",
    "                + loss_fun(u_x_reshaped[0, :], u_x_reshaped[Nx-1,:]) \n",
    "        \n",
    "        # compute the IC loss\n",
    "        x_reshaped = x.view(Nx, Nt)\n",
    "        u_initial = torch.sin(2 * np.pi * x_reshaped[:,0])\n",
    "        ic_loss = loss_fun(u_initial, u_reshaped[:,0])\n",
    "    \n",
    "        return pde_loss, bc_loss, ic_loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
