{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINNs) with Fourier Feature Mapping\n",
    "\n",
    "This notebook implements a Physics-Informed Neural Network (PINN) to solve partial differential equations (PDEs) using Fourier feature mapping. The notebook uses PyTorch for defining and training the network.\n",
    "\n",
    "```python\n",
    "\n",
    "$$\\frac {\\partial u} {\\partial t} +u* \\frac {\\partial u} {\\partial x} + v*\\frac {\\partial u} {\\partial y}- \\mu *(\\frac {\\partial^2 u} {\\partial x^2}  +{\\partial^2 u} {\\partial y^2})   = 0$$\n",
    "\n",
    "$$\\frac {\\partial v} {\\partial t} +u* \\frac {\\partial v} {\\partial x} + v*\\frac {\\partial v} {\\partial y}- \\mu *(\\frac {\\partial^2 v} {\\partial x^2}  +{\\partial^2 v} {\\partial y^2})   = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Fourier Feature Mapping Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFM(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, std_dev=2):\n",
    "        \"\"\"\n",
    "        Initializes the Fourier Feature Mapping.\n",
    "        \n",
    "        Parameters:\n",
    "        in_dim (int): Input dimensions (number of independent variables)\n",
    "        out_dim (int): Output dimensions (length of the hidden layer)\n",
    "        std_dev (float): Standard deviation for initializing omega parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.omega = nn.Parameter(torch.randn(out_dim, in_dim) * std_dev)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the Fourier feature mapping layer.\n",
    "        \n",
    "        Parameters:\n",
    "        x (Tensor): Input tensor\n",
    "        \n",
    "        Returns:\n",
    "        Tensor: Output tensor after applying cosine function\n",
    "        \"\"\"\n",
    "        return torch.cos(F.F.linear(x, self.omega))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the PINNs Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNsNet(nn.Module):\n",
    "    def __init__(self, in_dim=3, HL_dim=32, out_dim=2, activation=nn.Tanh()):\n",
    "        \"\"\"\n",
    "        Initializes the PINNs network.\n",
    "        \n",
    "        Parameters:\n",
    "        in_dim (int): Input dimensions (number of independent variables)\n",
    "        HL_dim (int): Width of the network (number of hidden layer units)\n",
    "        out_dim (int): Output dimensions (number of dependent variables)\n",
    "        activation (nn.Module): Activation function to use in the network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the network architecture\n",
    "        network = [nn.Linear(in_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, HL_dim), activation,\n",
    "                   nn.Linear(HL_dim, out_dim)]\n",
    "        \n",
    "        # Define the network using the sequential method\n",
    "        self.u = nn.Sequential(*network)\n",
    "        self.v = nn.Sequential(*network)\n",
    "    \n",
    "    def forward(self, r,theta, t):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Parameters:\n",
    "        x (Tensor): Spatial coordinates\n",
    "        y (Tensor): Spatial coordinates\n",
    "        t (Tensor): Temporal coordinates\n",
    "        \n",
    "        Returns:\n",
    "        Tensor: Network output\n",
    "        \"\"\"\n",
    "        return self.u(torch.cat((r,theta, t), 1)) , self.v(torch.cat((r,theta, t), 1))\n",
    "    \n",
    "    def compute_loss(self, r,theta, t, Nr,Ntheta, Nt):\n",
    "        \"\"\"\n",
    "        Computes the loss for the network.\n",
    "        \n",
    "        Parameters:\n",
    "        x (Tensor): Spatial coordinates with gradient tracking enabled\n",
    "        t (Tensor): Temporal coordinates with gradient tracking enabled\n",
    "        Nx (int): Number of spatial points\n",
    "        Nt (int): Number of temporal points\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Losses for PDE, boundary conditions, and initial conditions\n",
    "        \"\"\"\n",
    "        miu=0.1\n",
    "        r.requires_grad = True\n",
    "        theta.requires_grad = True\n",
    "        t.requires_grad = True\n",
    "        x = r*torch.cos(theta)\n",
    "        y=r*torch.sin(theta)\n",
    "\n",
    "        u = self.u(torch.cat((x,y, t), 1))\n",
    "        v = self.v(torch.cat((x,y, t), 1))\n",
    "        # Compute PDE derivatives using auto-grad\n",
    "        u_t = grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_x = grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_y = grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        u_yy = grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
    "        \n",
    "        v_t = grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_x = grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_y = grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        v_yy = grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "        u_r=grad(u, r, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_theta=grad(u, theta, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        v_r=grad(v, r, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_theta=grad(v, theta, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "        # Define a loss function\n",
    "        loss_fun = nn.MSELoss()\n",
    "\n",
    "        # Compute the PDE residual loss\n",
    "        resx = u_t + u*u_x + v*u_y - miu * (u_xx + u_yy)\n",
    "        resy = v_t + u*v_x + v*v_y - miu * (v_xx + v_yy)\n",
    "        pde_x_loss = loss_fun(resx, torch.zeros_like(resx))\n",
    "        pde_y_loss = loss_fun(resy, torch.zeros_like(resy))\n",
    "        # Compute the boundary condition (BC) loss\n",
    "        u_reshape = u.view(Nr,Ntheta,Nt)\n",
    "        v_reshape = v.view(Nr,Ntheta,Nt)\n",
    "        u_theta_reshape = u_theta.view(Nr,Ntheta,Nt)\n",
    "        v_theta_reshape = v_theta.view(Nr,Ntheta,Nt)\n",
    "        u_r_reshape = u_theta.view(Nr,Ntheta,Nt)\n",
    "        v_r_reshape = v_theta.view(Nr,Ntheta,Nt)\n",
    "\n",
    "        bc_loss= (loss_fun(u_reshape[r==R ,:,:], torch.zeros_like(u_reshape[0,:, :])) +\n",
    "                   loss_fun(v_reshape[r==R ,:,:], torch.zeros_like(v_reshape[0,:, :])) + \n",
    "                   loss_fun(u_theta_reshape[r==R ,:,:], torch.zeros_like(u_theta_reshape[0,:, :])) +\n",
    "                   loss_fun(v_theta_reshape[r==R ,:,:], torch.zeros_like(v_theta_reshape[0,:, :])) +\n",
    "                   loss_fun(u_r_reshape[r==R ,:,:], torch.zeros_like(u_r_reshape[0,:, :])) +\n",
    "                   loss_fun(v_r_reshape[r==R ,:,:], torch.zeros_like(v_r_reshape[0,:, :])) +\n",
    "                   loss_fun(v_r_reshape[Nr-1 ,:,:], torch.zeros_like(v_reshape[Nr-1,:, :]))+\n",
    "                   loss_fun(u_reshape[Nr-1 ,0,:], u_reshape[Nr-1 ,:,:]))\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute the initial condition (IC) loss\n",
    "        x_reshaped = x.view(Nr, Ntheta,Nt)\n",
    "        u_initial = 10*u.view(Nr,Ntheta,Nt)[:,:, 0]\n",
    "        ic_loss = loss_fun(u_initial, u.view(Nr,Ntheta,Nt)[:,:, 0])\n",
    "    \n",
    "        return pde_loss, bc_loss, ic_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINNsNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points in the domain\n",
    "Nx, Ny, Nt = 20, 20, 20\n",
    "Ntheta , Nr= 20, 20\n",
    "R=0.1\n",
    "Lr_initial, Lr_final = R, (2**0.5)\n",
    "Ltheta_initial, Ltheta_final = 0, 2*np.pi\n",
    "t_initial, t_final = 0, 2\n",
    "dr = (Lr_final - Lr_initial) / (Nr - 1)\n",
    "dtheta = (Ltheta_final - Ltheta_initial) / (Ntheta - 1)\n",
    "dt = (t_final - t_initial) / (Nt - 1)\n",
    "\n",
    "# Initialize input parameters as tensors\n",
    "r = torch.zeros(Nr,Ntheta, Nt)\n",
    "theta = torch.zeros(Nr,Ntheta, Nt)\n",
    "t = torch.zeros(Nr,Ntheta, Nt)\n",
    "for i in range(Nr):\n",
    "    for j in range(Ntheta):\n",
    "        for k in range(Nt):\n",
    "            r[i, j, k] = Lr_initial + dr * i\n",
    "            theta[i, j, k] = Ltheta_initial + dtheta * j\n",
    "            t[i, j, k] = t_initial + dt * k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[20, 20, 20]' is invalid for input of size 16000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Compute various losses\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     eq_loss, BC_loss, IC_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute total loss\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m eq_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m BC_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m IC_loss\n",
      "Cell \u001b[1;32mIn[3], line 88\u001b[0m, in \u001b[0;36mPINNsNet.compute_loss\u001b[1;34m(self, r, theta, t, Nr, Ntheta, Nt)\u001b[0m\n\u001b[0;32m     86\u001b[0m pde_y_loss \u001b[38;5;241m=\u001b[39m loss_fun(resy, torch\u001b[38;5;241m.\u001b[39mzeros_like(resy))\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Compute the boundary condition (BC) loss\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m u_reshape \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m v_reshape \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(Nr,Ntheta,Nt)\n\u001b[0;32m     90\u001b[0m u_theta_reshape \u001b[38;5;241m=\u001b[39m u_theta\u001b[38;5;241m.\u001b[39mview(Nr,Ntheta,Nt)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[20, 20, 20]' is invalid for input of size 16000"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    # Compute various losses\n",
    "    eq_loss, BC_loss, IC_loss = model.compute_loss(r.view(-1, 1),theta.view(-1, 1), t.view(-1, 1),Nr, Ntheta, Nt)\n",
    "    # Compute total loss\n",
    "    total_loss = eq_loss + 20 * BC_loss + 20 * IC_loss\n",
    "\n",
    "    # Backward pass\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Print epoch and loss\n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
